{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GBOGEB/GBOGEB-profile/blob/main/Digital_Twin_Parser_Starter_Pack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bvZibM-D7IEd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "kljhlkjh"
      ],
      "metadata": {
        "id": "eVtGlIcn7JyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- your_document_project/main.py ---\n",
        "# This is the core script for your Digital Twin Parser.\n",
        "# It will orchestrate the conversion from DOCX to structured data and then to Markdown.\n",
        "\n",
        "import os\n",
        "import json\n",
        "from typing import Dict, Any, List\n",
        "\n",
        "# Placeholder for actual parsing logic\n",
        "# You will integrate python-docx and your custom parsing logic here.\n",
        "\n",
        "def docx_to_structured_data(docx_path: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Stub function to simulate DOCX parsing into structured data.\n",
        "    In a real implementation, this would use python-docx to extract\n",
        "    content, styles, list numbering, and attempt to interpret SEQ/LISTNUM fields.\n",
        "    \"\"\"\n",
        "    print(f\"DEBUG: Parsing DOCX file: {docx_path}\")\n",
        "    # Example structure, replace with actual parsing logic\n",
        "    structured_data = {\n",
        "        \"metadata\": {\n",
        "            \"title\": \"MYRRHA Cryoplant Technical Requirements\",\n",
        "            \"source_file\": os.path.basename(docx_path),\n",
        "            \"version\": \"1.0.0\"\n",
        "        },\n",
        "        \"content_blocks\": [\n",
        "            {\n",
        "                \"type\": \"heading\",\n",
        "                \"level\": 1,\n",
        "                \"word_style\": \"Heading 1\",\n",
        "                \"outline_number\": \"1\",\n",
        "                \"text\": \"Introduction\",\n",
        "                \"location_id\": \"h1-intro\",\n",
        "                \"line_start\": 1,\n",
        "                \"properties\": {\"font_size\": \"24pt\", \"color\": \"#003f5c\"} # Example style from 'energetic & playful'\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"paragraph\",\n",
        "                \"word_style\": \"Normal\",\n",
        "                \"text\": \"This document outlines the technical requirements for the MYRRHA Cryoplant (QPLANT) based on the Deep Research report.\",\n",
        "                \"location_id\": \"p-intro-1\",\n",
        "                \"line_start\": 2,\n",
        "                \"properties\": {\"font_size\": \"12pt\", \"color\": \"#374c80\"}\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"list_item\",\n",
        "                \"list_type\": \"numbered\",\n",
        "                \"list_level\": 1,\n",
        "                \"list_number\": \"1.1\",\n",
        "                \"word_style\": \"List Paragraph\",\n",
        "                \"text\": \"The LINAC system overview.\",\n",
        "                \"location_id\": \"li-linac-overview\",\n",
        "                \"line_start\": 3,\n",
        "                \"properties\": {\"font_size\": \"12pt\", \"color\": \"#374c80\"}\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"table\",\n",
        "                \"location_id\": \"table-cold-masses\",\n",
        "                \"title\": \"Table 19 Cold masses at 4.5 K / 2 K\",\n",
        "                \"headers\": [\"Estimated weight\", \"Cryomodule (QM)\", \"For 1 QM\", \"Cold Valve Box (QVB)\", \"For 1 QM\", \"Cryogenic lines 4.5 K pipes\", \"TOTAL cold mass for 30 cryomodules (4.5 K-2 K)\"],\n",
        "                \"rows\": [\n",
        "                    [\"Stainless Steel (kg)\", \"80\", \"60\", \"2 800\", \"7 000\", \"NA\", \"NA\"],\n",
        "                    [\"Niobium (kg)\", \"80\", \"NA\", \"NA\", \"2 400\", \"NA\", \"NA\"],\n",
        "                    [\"Titanium (kg)\", \"40\", \"NA\", \"NA\", \"1 200\", \"NA\", \"NA\"],\n",
        "                    [\"Total (kg)\", \"200\", \"60\", \"2 800\", \"10 600\", \"NA\", \"NA\"]\n",
        "                ],\n",
        "                \"line_start\": 100,\n",
        "                \"properties\": {}\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "    return structured_data\n",
        "\n",
        "def structured_data_to_markdown(structured_data: Dict[str, Any]) -> str:\n",
        "    \"\"\"\n",
        "    Stub function to convert structured data into Markdown.\n",
        "    This would handle headings, paragraphs, lists, and embedding HTML for complex elements.\n",
        "    \"\"\"\n",
        "    print(\"DEBUG: Converting structured data to Markdown...\")\n",
        "    markdown_content = []\n",
        "    for block in structured_data.get(\"content_blocks\", []):\n",
        "        block_type = block.get(\"type\")\n",
        "        text = block.get(\"text\", \"\")\n",
        "        location_id = block.get(\"location_id\", \"\")\n",
        "        outline_number = block.get(\"outline_number\", \"\")\n",
        "\n",
        "        if block_type == \"heading\":\n",
        "            level = block.get(\"level\", 1)\n",
        "            markdown_content.append(f\"{'#' * level} {outline_number} {text} {{#{location_id}}}\")\n",
        "        elif block_type == \"paragraph\":\n",
        "            markdown_content.append(f\"{text}\\n\")\n",
        "        elif block_type == \"list_item\":\n",
        "            list_type = block.get(\"list_type\", \"unordered\")\n",
        "            list_number = block.get(\"list_number\", \"\")\n",
        "            prefix = f\"{list_number}. \" if list_type == \"numbered\" else \"- \"\n",
        "            markdown_content.append(f\"{prefix}{text}\")\n",
        "        elif block_type == \"table\":\n",
        "            title = block.get(\"title\", \"Table\")\n",
        "            headers = block.get(\"headers\", [])\n",
        "            rows = block.get(\"rows\", [])\n",
        "            # For complex tables, embedding HTML is often best\n",
        "            markdown_content.append(f\"\\n### {title} {{#{location_id}}}\")\n",
        "            markdown_content.append(\"<table>\")\n",
        "            markdown_content.append(\"  <thead><tr>\")\n",
        "            for header in headers:\n",
        "                markdown_content.append(f\"    <th>{header}</th>\")\n",
        "            markdown_content.append(\"  </tr></thead>\")\n",
        "            markdown_content.append(\"  <tbody>\")\n",
        "            for row in rows:\n",
        "                markdown_content.append(\"    <tr>\")\n",
        "                for cell in row:\n",
        "                    markdown_content.append(f\"      <td>{cell}</td>\")\n",
        "                markdown_content.append(\"    </tr>\")\n",
        "            markdown_content.append(\"  </tbody>\")\n",
        "            markdown_content.append(\"</table>\\n\")\n",
        "\n",
        "    return \"\\n\".join(markdown_content)\n",
        "\n",
        "def main_process(docx_path: str, output_md_path: str, output_json_path: str):\n",
        "    \"\"\"\n",
        "    Main function to orchestrate the parsing and conversion process.\n",
        "    \"\"\"\n",
        "    print(f\"INFO: Starting digital twin parsing for '{docx_path}'...\")\n",
        "\n",
        "    # Step 1: DOCX to Structured Data\n",
        "    structured_data = docx_to_structured_data(docx_path)\n",
        "    with open(output_json_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(structured_data, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"INFO: Structured data saved to '{output_json_path}'\")\n",
        "\n",
        "    # Step 2: Structured Data to Markdown\n",
        "    markdown_content = structured_data_to_markdown(structured_data)\n",
        "    with open(output_md_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(markdown_content)\n",
        "    print(f\"INFO: Markdown output saved to '{output_md_path}'\")\n",
        "\n",
        "    print(\"INFO: Digital twin parsing complete.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage:\n",
        "    # Ensure 'input/0604_parseme.docx' exists for a real test\n",
        "    input_docx = os.path.join('input', '0604_parseme.docx')\n",
        "    output_markdown = os.path.join('output', 'MAIN.md')\n",
        "    output_structured_json = os.path.join('output', 'MAIN_STRUCTURED_DATA.json')\n",
        "\n",
        "    # Create input and output directories if they don't exist\n",
        "    os.makedirs('input', exist_ok=True)\n",
        "    os.makedirs('output', exist_ok=True)\n",
        "\n",
        "    # Simulate creation of the input DOCX for testing without actual file\n",
        "    if not os.path.exists(input_docx):\n",
        "        print(f\"WARNING: Input DOCX '{input_docx}' not found. Using dummy data.\")\n",
        "        # Create a dummy file or skip actual parsing if not present\n",
        "        # In a real scenario, you'd need the actual .docx file.\n",
        "        # For this stub, docx_to_structured_data is mocked.\n",
        "        pass\n",
        "\n",
        "    main_process(input_docx, output_markdown, output_structured_json)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Input DOCX 'input/0604_parseme.docx' not found. Using dummy data.\n",
            "INFO: Starting digital twin parsing for 'input/0604_parseme.docx'...\n",
            "DEBUG: Parsing DOCX file: input/0604_parseme.docx\n",
            "INFO: Structured data saved to 'output/MAIN_STRUCTURED_DATA.json'\n",
            "DEBUG: Converting structured data to Markdown...\n",
            "INFO: Markdown output saved to 'output/MAIN.md'\n",
            "INFO: Digital twin parsing complete.\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b44Db9aG5F_B",
        "outputId": "6c9ca6f9-6693-40ac-fca8-fcf47fa902aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- your_document_project/cli_wrapper.py ---\n",
        "# This script provides a command-line interface (CLI) for your main parsing logic.\n",
        "# It uses Python's built-in argparse for easy argument handling.\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "from main import main_process # Import the core function\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Digital Twin Parser: Convert DOCX documents to structured data and Markdown.\",\n",
        "        formatter_class=argparse.RawTextHelpFormatter\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"input_docx\",\n",
        "        type=str,\n",
        "        help=\"Path to the input DOCX file (e.g., input/MAIN_INPUT.docx)\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output-md\",\n",
        "        type=str,\n",
        "        default=os.path.join('output', 'MAIN.md'),\n",
        "        help=\"Path for the output Markdown file (default: output/MAIN.md)\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output-json\",\n",
        "        type=str,\n",
        "        default=os.path.join('output', 'MAIN_STRUCTURED_DATA.json'),\n",
        "        help=\"Path for the output structured JSON file (default: output/MAIN_STRUCTURED_DATA.json)\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--debug\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Enable debug mode for more verbose output.\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--config\",\n",
        "        type=str,\n",
        "        default=\"config.py\",\n",
        "        help=\"Path to a custom configuration file (default: config.py)\"\n",
        "    )\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Load configuration (simple example)\n",
        "    try:\n",
        "        # This is a basic way to load a config. For more complex configs,\n",
        "        # consider using a dedicated config parser or importlib.\n",
        "        config_module_name = os.path.splitext(os.path.basename(args.config))[0]\n",
        "        # Temporarily add config directory to path to import\n",
        "        import sys\n",
        "        sys.path.insert(0, os.path.dirname(args.config))\n",
        "        config = __import__(config_module_name)\n",
        "        sys.path.pop(0)\n",
        "        print(f\"DEBUG: Loaded configuration from {args.config}\")\n",
        "        # Apply config settings if needed, e.g., config.DEBUG_MODE = args.debug\n",
        "    except ImportError:\n",
        "        print(f\"WARNING: Configuration file '{args.config}' not found or could not be loaded. Using default settings.\")\n",
        "        # Fallback to default settings or raise an error\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Failed to load configuration: {e}\")\n",
        "\n",
        "    # Ensure output directories exist\n",
        "    os.makedirs(os.path.dirname(args.output_md), exist_ok=True)\n",
        "    os.makedirs(os.path.dirname(args.output_json), exist_ok=True)\n",
        "\n",
        "    main_process(args.input_docx, args.output_md, args.output_json)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'main'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7a87b7e165ce>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmain_process\u001b[0m \u001b[0;31m# Import the core function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'main'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "uz5LduiV5F_G",
        "outputId": "39d676f9-0867-47aa-d708-dc3ca15015d4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- your_document_project/setup.py ---\n",
        "# This file is for Python package installation.\n",
        "# It defines how your project can be installed using pip.\n",
        "\n",
        "from setuptools import setup, find_packages\n",
        "\n",
        "setup(\n",
        "    name='digital_twin_parser',\n",
        "    version='0.1.0',\n",
        "    packages=find_packages(),\n",
        "    include_package_data=True,\n",
        "    install_requires=[\n",
        "        'python-docx', # For DOCX parsing\n",
        "        # Add other dependencies here, e.g., 'pandas', 'lxml'\n",
        "    ],\n",
        "    entry_points={\n",
        "        'console_scripts': [\n",
        "            'dtparser=cli_wrapper:main',\n",
        "        ],\n",
        "    },\n",
        "    author='Your Name',\n",
        "    author_email='your.email@example.com',\n",
        "    description='A tool to create a digital twin of Word documents in Markdown.',\n",
        "    long_description=open('main_readme.md').read(),\n",
        "    long_description_content_type='text/markdown',\n",
        "    url='https://github.com/yourusername/your_document_project', # Replace with your repo URL\n",
        "    classifiers=[\n",
        "        'Programming Language :: Python :: 3',\n",
        "        'License :: OSI Approved :: MIT License',\n",
        "        'Operating System :: OS Independent',\n",
        "        'Development Status :: 3 - Alpha',\n",
        "        'Intended Audience :: Developers',\n",
        "        'Topic :: Text Processing',\n",
        "        'Topic :: Software Development :: Libraries :: Python Modules',\n",
        "    ],\n",
        "    python_requires='>=3.7',\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'main_readme.md'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b3ed936b6f7d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mauthor_email\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'your.email@example.com'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'A tool to create a digital twin of Word documents in Markdown.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mlong_description\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'main_readme.md'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mlong_description_content_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'text/markdown'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'https://github.com/yourusername/your_document_project'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Replace with your repo URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'main_readme.md'"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "keb-2WaT5F_G",
        "outputId": "9578a459-7aba-451b-8686-815a9275bd50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "OQlh_TcT54UE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "j6djJCJX54-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- your_document_project/config.py ---\n",
        "# This file holds configuration settings for your application.\n",
        "# You can define constants, paths, and other parameters here.\n",
        "\n",
        "# Debugging settings\n",
        "DEBUG_MODE = True\n",
        "LOG_LEVEL = \"INFO\" # Options: \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"\n",
        "\n",
        "# Paths\n",
        "INPUT_DOCX_DIR = \"input\"\n",
        "OUTPUT_DIR = \"output\"\n",
        "PARSED_JSON_FILENAME = \"MAIN_STRUCTURED_DATA.json\"\n",
        "MARKDOWN_FILENAME = \"MAIN.md\"\n",
        "\n",
        "# Parsing specific configurations\n",
        "# Example: Max characters for label wrapping in charts (if integrated here)\n",
        "MAX_LABEL_CHARS = 16\n",
        "\n",
        "# Style configurations (for HTML rendering, if generated from JSON/YAML)\n",
        "# This would typically be loaded from a separate JSON/YAML file,\n",
        "# but can be defined here for simple cases.\n",
        "STYLES = {\n",
        "    \"Heading 1\": {\"font_size\": \"24pt\", \"color\": \"#003f5c\"},\n",
        "    \"Normal\": {\"font_size\": \"12pt\", \"color\": \"#374c80\"},\n",
        "    \"List Paragraph\": {\"font_size\": \"12pt\", \"color\": \"#7a5195\"}\n",
        "}\n",
        "\n",
        "# Future feature stubs configuration\n",
        "ENABLE_IMAGE_PROCESSING = False\n",
        "ENABLE_LUA_FILTERS = False\n",
        "ENABLE_ROUNDTRIP_CONVERSION = False"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "id": "qUvf17Qw5F_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "https://colab.research.google.com/drive/1F1-eepeEMWLbGRL9GEqI-frkxHYyX6sd#scrollTo=qUvf17Qw5F_G&line=1&uniqifier=1"
      ],
      "metadata": {
        "id": "hMIaXYVc6L5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- your_document_project/debug.py ---\n",
        "# This file provides basic debugging utilities.\n",
        "# You can add more sophisticated logging or inspection tools here.\n",
        "\n",
        "import inspect\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "def log_message(level: str, message: str, data: Any = None):\n",
        "    \"\"\"\n",
        "    Logs a message with a specified level.\n",
        "    \"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    caller_frame = inspect.currentframe().f_back\n",
        "    caller_name = caller_frame.f_code.co_name if caller_frame else \"unknown\"\n",
        "    file_name = os.path.basename(caller_frame.f_code.co_filename) if caller_frame else \"unknown\"\n",
        "\n",
        "    log_output = f\"[{timestamp}] [{level.upper()}] [{file_name}:{caller_name}] {message}\"\n",
        "\n",
        "    if data is not None:\n",
        "        try:\n",
        "            log_output += f\"\\nData: {json.dumps(data, indent=2, ensure_ascii=False)}\"\n",
        "        except TypeError:\n",
        "            log_output += f\"\\nData: {str(data)}\"\n",
        "\n",
        "    print(log_output)\n",
        "\n",
        "def debug_print(message: str, data: Any = None):\n",
        "    \"\"\"\n",
        "    Prints a debug message if DEBUG_MODE is enabled in config.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from config import DEBUG_MODE\n",
        "        if DEBUG_MODE:\n",
        "            log_message(\"DEBUG\", message, data)\n",
        "    except ImportError:\n",
        "        log_message(\"DEBUG\", \"Config not loaded. Printing debug message anyway.\", da"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-9-fc720d46363f>, line 37)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-fc720d46363f>\"\u001b[0;36m, line \u001b[0;32m37\u001b[0m\n\u001b[0;31m    log_message(\"DEBUG\", \"Config not loaded. Printing debug message anyway.\", da\u001b[0m\n\u001b[0m                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "ESEZ9d2W5F_H",
        "outputId": "086b2579-ac9c-4f98-8a43-1a45fdc4b66f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "dh6GFl067C-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "7N0rKC6L7FkU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T9QKnYuH6ja-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mXO7NEoB6jza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V_LB9f1L6j8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "22Po_m8p6kmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wddEoxsq6k2V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qXbLnUsd6lDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aBgKyD-z6lMV"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}